{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd70c58-3d97-482d-98d0-b25989e02db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e06cad3e-c9d2-448a-9f6b-07f3cbed942a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBCLASS</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>AARS1</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>KIPAN</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>SARC</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>SKCM</td>\n",
       "      <td>R895R</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>KIRC</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>GBMLGG</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID SUBCLASS    A2M AAAS AADAT AARS1 ABAT ABCA1 ABCA2 ABCA3  ...  \\\n",
       "0  TRAIN_0000    KIPAN     WT   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "1  TRAIN_0001     SARC     WT   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "2  TRAIN_0002     SKCM  R895R   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "3  TRAIN_0003     KIRC     WT   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "4  TRAIN_0004   GBMLGG     WT   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "\n",
       "  ZNF292 ZNF365 ZNF639 ZNF707 ZNFX1 ZNRF4 ZPBP ZW10 ZWINT ZYX  \n",
       "0     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "1     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "2     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "3     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "4     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "\n",
       "[5 rows x 4386 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data./train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5f9cdc-23a0-4473-b4bf-36ef26bd56ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>AARS1</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>R587Q</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>I383Sfs</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID A2M AAAS AADAT AARS1 ABAT  ABCA1 ABCA2 ABCA3 ABCA4  ... ZNF292  \\\n",
       "0  TEST_0000  WT   WT    WT    WT   WT     WT    WT    WT    WT  ...     WT   \n",
       "1  TEST_0001  WT   WT    WT    WT   WT  R587Q    WT    WT    WT  ...     WT   \n",
       "2  TEST_0002  WT   WT    WT    WT   WT     WT    WT    WT    WT  ...     WT   \n",
       "3  TEST_0003  WT   WT    WT    WT   WT     WT    WT    WT    WT  ...     WT   \n",
       "4  TEST_0004  WT   WT    WT    WT   WT     WT    WT    WT    WT  ...     WT   \n",
       "\n",
       "  ZNF365 ZNF639 ZNF707 ZNFX1    ZNRF4 ZPBP ZW10 ZWINT ZYX  \n",
       "0     WT     WT     WT    WT       WT   WT   WT    WT  WT  \n",
       "1     WT     WT     WT    WT  I383Sfs   WT   WT    WT  WT  \n",
       "2     WT     WT     WT    WT       WT   WT   WT    WT  WT  \n",
       "3     WT     WT     WT    WT       WT   WT   WT    WT  WT  \n",
       "4     WT     WT     WT    WT       WT   WT   WT    WT  WT  \n",
       "\n",
       "[5 rows x 4385 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = pd.read_csv('./data./test.csv')\n",
    "t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b27ca1-aed2-4751-b65b-3726322604b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번 시도: 문제 있는 것들을 모두 mutation으로 변형 후 모델링 돌려보자\n",
    "# df 복제하기\n",
    "df_1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6906a58a-b808-4cea-8208-9837665c244f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBCLASS</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>AARS1</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mutation</td>\n",
       "      <td>Mutation</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mutation</td>\n",
       "      <td>Mutation</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mutation</td>\n",
       "      <td>Mutation</td>\n",
       "      <td>Mutation</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mutation</td>\n",
       "      <td>Mutation</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mutation</td>\n",
       "      <td>Mutation</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  SUBCLASS       A2M AAAS AADAT AARS1 ABAT ABCA1 ABCA2 ABCA3  ...  \\\n",
       "0  Mutation  Mutation        WT   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "1  Mutation  Mutation        WT   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "2  Mutation  Mutation  Mutation   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "3  Mutation  Mutation        WT   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "4  Mutation  Mutation        WT   WT    WT    WT   WT    WT    WT    WT  ...   \n",
       "\n",
       "  ZNF292 ZNF365 ZNF639 ZNF707 ZNFX1 ZNRF4 ZPBP ZW10 ZWINT ZYX  \n",
       "0     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "1     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "2     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "3     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "4     WT     WT     WT     WT    WT    WT   WT   WT    WT  WT  \n",
       "\n",
       "[5 rows x 4386 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mutation으로 변경하기\n",
    "df_1 = df_1.applymap(lambda x: 'Mutation' if x != 'WT' else x)\n",
    "\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12819ed-20bd-41a9-9875-7cc88678347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Trial : RandomForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7307cfa-b8b5-4ac3-b101-d2706e84e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature, Target split\n",
    "X = df_1.drop(columns=['SUBCLASS'])\n",
    "y = df_1['SUBCLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95163a2d-fdd2-4a32-a337-3ebed3fdeb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding이용해서 범주형 데이터를 수치형으로 변환\n",
    "# label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af6fc3f-2817-4d71-83ee-656ca6df4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 각 열에 대해 : LAbel Encoding 적용\n",
    "label_encoders = {}\n",
    "for col in X.columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d4cc664-6dde-4f76-87ab-0716dacaf0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b233b4f-6288-4c8b-a726-293d658dbf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Train\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d81ebe5e-b623-4540-9a23-b381a264cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# 예측 및 평가\n",
    "y_pred = rf_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a322ad30-2a29-4744-857c-ea3de1489b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      " [[1241]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 교차 검증을 사용하여 F1 스코어 평가\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "print(f'Cross-validated F1 Score: {cv_scores.mean():.2f}')\n",
    "\n",
    "# 예측 및 Confusion Matrix 확인\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374a0c60-b7ec-4eaa-8ace-b50d67f81a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Encode 'WT' and 'Mutation' values\n",
    "df_encoded = df.copy()\n",
    "for col in df_encoded.columns[2:]:  # Skip 'ID' and 'SUBCLASS' columns\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "# Encode the target variable 'SUBCLASS'\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded['SUBCLASS'] = label_encoder.fit_transform(df_encoded['SUBCLASS'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_encoded.drop(['ID', 'SUBCLASS'], axis=1)\n",
    "y = df_encoded['SUBCLASS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1f2e52-530a-4700-8a02-829dcd311a27",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m X_test_final \u001b[38;5;241m=\u001b[39m t_df_encoded\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Predict the SUBCLASS for the test data using the trained model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m t_df_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBCLASS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Decode the predicted 'SUBCLASS' back to original labels using the trained label_encoder\u001b[39;00m\n\u001b[0;32m     16\u001b[0m t_df_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBCLASS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(t_df_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBCLASS\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Load the test data (t_df)\n",
    "# t_df = pd.read_csv(\"test.csv\")  # Replace with your actual file path\n",
    "\n",
    "# Manually encode 'WT' and 'Mutation' for the test set based on training data's encoding\n",
    "t_df_encoded = t_df.copy()\n",
    "for col in t_df_encoded.columns[1:]:  # Skip 'ID' column\n",
    "    t_df_encoded[col] = t_df_encoded[col].map({'WT': 0, 'Mutation': 1})\n",
    "\n",
    "# Prepare the test features\n",
    "X_test_final = t_df_encoded.drop(['ID'], axis=1)\n",
    "\n",
    "# Predict the SUBCLASS for the test data using the trained model\n",
    "t_df_encoded['SUBCLASS'] = rf_model.predict(X_test_final)\n",
    "\n",
    "# Decode the predicted 'SUBCLASS' back to original labels using the trained label_encoder\n",
    "t_df_encoded['SUBCLASS'] = label_encoder.inverse_transform(t_df_encoded['SUBCLASS'])\n",
    "\n",
    "# Create the submission file\n",
    "submission = t_df[['ID']].copy()\n",
    "submission['SUBCLASS'] = t_df_encoded['SUBCLASS']\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8049a-6bae-49e1-a0a8-41d8de0c36bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
